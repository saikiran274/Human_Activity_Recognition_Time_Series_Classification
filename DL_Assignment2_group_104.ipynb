{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    " \n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded\n",
    " \n",
    "# load a dataset group\n",
    "def load_dataset(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/Inertial Signals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y\n",
    " \n",
    "# load all train\n",
    "trainX, trainy = load_dataset('train', 'HARDataset/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load all test\n",
    "testX, testy = load_dataset('test', 'HARDataset/')\n",
    "print(testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: Develop an LSTM Network Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.5)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('path of the file')\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "reshaped_segments = np.asarray(segments, dtype = np.float32).reshape( -1 , N_time_steps, N_features)\n",
    "\n",
    "reshaped_segments.shape\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( reshaped_segments, labels, test_size = 0.2, random_state = RANDOM_SEED)\n",
    "\n",
    "def create_LSTM_model(inputs):\n",
    "\n",
    "    W = {\n",
    "\n",
    "        'hidden': tf.Variable(tf.random_normal([N_features, N_hidden_units])),\n",
    "\n",
    "        'output': tf.Variable(tf.random_normal([N_hidden_units, N_classes]))\n",
    "\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "\n",
    "        'hidden': tf.Variable(tf.random_normal([N_hidden_units], mean = 0.1)),\n",
    "\n",
    "        'output': tf.Variable(tf.random_normal([N_classes]))\n",
    "\n",
    "    }\n",
    "\n",
    "    X = tf.transpose(inputs, [1, 0, 2])\n",
    "\n",
    "    X = tf.reshape(X, [-1, N_features])\n",
    "\n",
    "    hidden = tf.nn.relu(tf.matmul(X, W['hidden']) + biases['hidden'])\n",
    "\n",
    "    hidden = tf.split(hidden, N_time_steps, 0)\n",
    "\n",
    "    lstm_layers = [tf.contrib.rnn.BasicLSTMCell( N_hidden_units, forget_bias = 1.0) for _ in range(2)]\n",
    "\n",
    "    lstm_layers = tf.contrib.rnn.MultiRNNCell(lstm_layers)\n",
    "\n",
    "    outputs, _ = tf.contrib.rnn.static_rnn(lstm_layers, hidden, dtype = tf.float32)\n",
    "\n",
    "    lstm_last_output = outputs[-1]\n",
    "\n",
    "    return tf.matmul(lstm_last_output, W['output']) + biases['output']\n",
    "\n",
    "L2_LOSS = 0.0015\n",
    "\n",
    "l2 = L2_LOSS\n",
    "\n",
    "  sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( logits = pred_y, labels = Y)) + l2\n",
    "\n",
    "Learning_rate = 0.0025\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = Learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred_softmax , 1), tf.argmax(Y,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype = tf.float32))\n",
    "\n",
    "N_epochs = 50  \n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "history = dict(train_loss=[], train_acc=[], test_loss=[], test_acc=[])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_count = len(X_train)\n",
    "\n",
    "for i in range(1, N_epochs + 1):\n",
    "\n",
    "    for start, end in zip(range(0, train_count, batch_size), range(batch_size, train_count + 1, batch_size)):\n",
    "\n",
    "        sess.run(optimizer, feed_dict={X: X_train[start:end], Y: Y_train[start:end]})\n",
    "\n",
    "    _, acc_train, loss_train = sess.run([pred_softmax, accuracy, loss], feed_dict={\n",
    "\n",
    "        X: X_train, Y: Y_train})\n",
    "\n",
    "    _, acc_test, loss_test = sess.run([pred_softmax, accuracy, loss], feed_dict={\n",
    "\n",
    "        X: X_test, Y: Y_test})\n",
    "\n",
    "    history['train_loss'].append(loss_train)\n",
    "\n",
    "    history['train_acc'].append(acc_train)\n",
    "\n",
    "    history['test_loss'].append(loss_test)\n",
    "\n",
    "    history['test_acc'].append(acc_test)\n",
    "\n",
    "    if (i != 1 and i % 10 != 0):\n",
    "\n",
    "        print(f'epoch: {i} test_accuracy:{acc_test} loss:{loss_test}')\n",
    "\n",
    "predictions, acc_final, loss_final = sess.run([pred_softmax, accuracy, loss],\n",
    "\n",
    "                                              feed_dict={X: X_test, Y: Y_test})\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'final results : accuracy : {acc_final} loss : {loss_final}')     \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(np.array(history['train_loss']), \"r--\", label=\"Train loss\")\n",
    "\n",
    "plt.plot(np.array(history['train_acc']), \"g--\", label=\"Train accuracy\")\n",
    "\n",
    "plt.plot(np.array(history['test_loss']), \"r--\", label=\"Test loss\")\n",
    "\n",
    "plt.plot(np.array(history['test_acc']), \"g--\", label=\"Test accuracy\")\n",
    "\n",
    "plt.legend(loc = 'upper right', shadow = True)\n",
    "\n",
    "plt.ylabel('Training Progress(Loss or Accuracy values)')\n",
    "\n",
    "plt.xlabel('Training Epoch')\n",
    "\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.show()\n",
    "#Print confusion matrix\n",
    "max_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "max_predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions)\n",
    "\n",
    "plt.figure(figsize=(16,14))\n",
    "\n",
    "sns.heatmap(confusion_matrix, xticklabels = LABELS, yticklabels = LABELS, annot =True, fmt = \"d\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.xlabel('Predicted_label')\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
